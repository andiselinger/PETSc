************************************************************************************************************************
***             WIDEN YOUR WINDOW TO 120 CHARACTERS.  Use 'enscript -r -fCourier9' to print this document            ***
************************************************************************************************************************

---------------------------------------------- PETSc Performance Summary: ----------------------------------------------

ex2 on a arch-linux2-c-opt named n16-014 with 22 processors, by selinger3d Tue Aug 29 14:35:49 2017
Using Petsc Release Version 3.7.6, unknown 

                         Max       Max/Min        Avg      Total 
Time (sec):           1.871e-01      1.00395   1.864e-01
Objects:              5.190e+02      1.00000   5.190e+02
Flops:                4.373e+07      1.01805   4.338e+07  9.544e+08
Flops/sec:            2.347e+08      1.02202   2.327e+08  5.120e+09
MPI Messages:         1.430e+03      3.40882   1.059e+03  2.330e+04
MPI Message Lengths:  2.245e+06      2.14610   1.942e+03  4.526e+07
MPI Reductions:       7.000e+02      1.00000

Flop counting convention: 1 flop = 1 real number operation of type (multiply/divide/add/subtract)
                            e.g., VecAXPY() for real vectors of length N --> 2N flops
                            and VecAXPY() for complex vectors of length N --> 8N flops

Summary of Stages:   ----- Time ------  ----- Flops -----  --- Messages ---  -- Message Lengths --  -- Reductions --
                        Avg     %Total     Avg     %Total   counts   %Total     Avg         %Total   counts   %Total 
 0:      Main Stage: 1.7503e-01  93.9%  9.5443e+08 100.0%  2.322e+04  99.6%  1.939e+03       99.8%  6.890e+02  98.4% 
 1:        Assembly: 1.1354e-02   6.1%  0.0000e+00   0.0%  8.400e+01   0.4%  3.699e+00        0.2%  1.000e+01   1.4% 

------------------------------------------------------------------------------------------------------------------------
See the 'Profiling' chapter of the users' manual for details on interpreting output.
Phase summary info:
   Count: number of times phase was executed
   Time and Flops: Max - maximum over all processors
                   Ratio - ratio of maximum to minimum over all processors
   Mess: number of messages sent
   Avg. len: average message length (bytes)
   Reduct: number of global reductions
   Global: entire computation
   Stage: stages of a computation. Set stages with PetscLogStagePush() and PetscLogStagePop().
      %T - percent time in this phase         %F - percent flops in this phase
      %M - percent messages in this phase     %L - percent message lengths in this phase
      %R - percent reductions in this phase
   Total Mflop/s: 10e-6 * (sum of flops over all processors)/(max time over all processors)
------------------------------------------------------------------------------------------------------------------------
Event                Count      Time (sec)     Flops                             --- Global ---  --- Stage ---   Total
                   Max Ratio  Max     Ratio   Max  Ratio  Mess   Avg len Reduct  %T %F %M %L %R  %T %F %M %L %R Mflop/s
------------------------------------------------------------------------------------------------------------------------

--- Event Stage 0: Main Stage

MatMult              330 1.0 1.6287e-02 1.2 1.38e+07 1.0 1.4e+04 2.2e+03 0.0e+00  8 31 58 67  0   9 31 58 67  0 18404
MatMultAdd            40 1.0 2.9309e-03 1.9 7.44e+05 1.0 1.4e+03 7.2e+02 0.0e+00  1  2  6  2  0   1  2  6  2  0  5530
MatMultTranspose      40 1.0 2.1062e-03 1.2 7.44e+05 1.0 1.4e+03 7.2e+02 0.0e+00  1  2  6  2  0   1  2  6  2  0  7695
MatSolve              10 0.0 5.1260e-05 0.0 2.75e+04 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0   537
MatSOR               284 1.0 1.8970e-02 1.0 1.15e+07 1.0 0.0e+00 0.0e+00 0.0e+00 10 26  0  0  0  11 26  0  0  0 13209
MatLUFactorSym         1 1.0 7.9155e-05 7.2 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
MatLUFactorNum         1 1.0 3.9101e-0520.5 2.68e+04 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0   686
MatConvert             4 1.0 1.6050e-03 1.7 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  1  0  0  0  0   1  0  0  0  0     0
MatScale              12 1.0 8.0061e-04 1.7 2.48e+05 1.0 1.6e+02 2.2e+03 0.0e+00  0  1  1  1  0   0  1  1  1  0  6719
MatResidual           40 1.0 2.0509e-03 1.1 1.73e+06 1.0 1.6e+03 2.2e+03 0.0e+00  1  4  7  8  0   1  4  7  8  0 18326
MatAssemblyBegin      81 1.0 9.2013e-03 6.9 0.00e+00 0.0 8.8e+02 2.5e+03 5.2e+01  3  0  4  5  7   3  0  4  5  8     0
MatAssemblyEnd        81 1.0 2.1219e-02 1.3 0.00e+00 0.0 1.8e+03 3.0e+02 1.7e+02 10  0  8  1 24  11  0  8  1 24     0
MatGetRow          41889 1.0 7.2749e-03 1.6 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  3  0  0  0  0   3  0  0  0  0     0
MatGetRowIJ            1 0.0 1.0014e-05 0.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
MatGetSubMatrix        4 1.0 2.2662e-03 1.0 0.00e+00 0.0 3.5e+02 6.7e+02 6.8e+01  1  0  1  1 10   1  0  2  1 10     0
MatGetOrdering         1 0.0 4.4107e-05 0.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
MatCoarsen             4 1.0 3.1688e-03 1.2 0.00e+00 0.0 1.3e+03 1.1e+03 1.8e+01  2  0  6  3  3   2  0  6  3  3     0
MatZeroEntries         4 1.0 1.8597e-05 1.4 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
MatAXPY                4 1.0 5.3661e-03 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 8.0e+00  3  0  0  0  1   3  0  0  0  1     0
MatMatMult             4 1.0 1.0012e-02 1.0 1.73e+05 1.0 1.0e+03 1.1e+03 6.4e+01  5  0  4  2  9   6  0  4  2  9   375
MatMatMultSym          4 1.0 8.2262e-03 1.0 0.00e+00 0.0 8.8e+02 8.8e+02 5.6e+01  4  0  4  2  8   5  0  4  2  8     0
MatMatMultNum          4 1.0 1.8291e-03 1.1 1.73e+05 1.0 1.6e+02 2.2e+03 8.0e+00  1  0  1  1  1   1  0  1  1  1  2055
MatPtAP                4 1.0 1.9856e-02 1.0 1.14e+06 1.1 2.3e+03 2.2e+03 6.8e+01 11  3 10 11 10  11  3 10 11 10  1221
MatPtAPSymbolic        4 1.0 1.3978e-02 1.0 0.00e+00 0.0 1.1e+03 2.6e+03 2.8e+01  7  0  5  6  4   8  0  5  6  4     0
MatPtAPNumeric         4 1.0 5.8870e-03 1.0 1.14e+06 1.1 1.2e+03 1.8e+03 4.0e+01  3  3  5  5  6   3  3  5  5  6  4119
MatTrnMatMult          1 1.0 2.6886e-02 1.0 6.05e+05 1.0 2.5e+02 6.5e+03 1.9e+01 14  1  1  4  3  15  1  1  4  3   494
MatTrnMatMultSym       1 1.0 1.8892e-02 1.0 0.00e+00 0.0 2.1e+02 3.7e+03 1.7e+01 10  0  1  2  2  11  0  1  2  2     0
MatTrnMatMultNum       1 1.0 8.0371e-03 1.0 6.05e+05 1.0 4.2e+01 2.0e+04 2.0e+00  4  1  0  2  0   5  1  0  2  0  1653
MatGetLocalMat        14 1.0 3.2659e-03 1.4 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  1  0  0  0  0   2  0  0  0  0     0
MatGetBrAoCol         12 1.0 1.5836e-03 1.3 0.00e+00 0.0 1.1e+03 2.8e+03 0.0e+00  1  0  5  7  0   1  0  5  7  0     0
VecMDot               89 1.0 5.7368e-03 1.6 4.14e+06 1.0 0.0e+00 0.0e+00 8.9e+01  2 10  0  0 13   2 10  0  0 13 15854
VecNorm               99 1.0 4.9462e-03 1.1 8.77e+05 1.0 0.0e+00 0.0e+00 9.9e+01  3  2  0  0 14   3  2  0  0 14  3890
VecScale              98 1.0 4.1056e-04 1.1 4.26e+05 1.0 0.0e+00 0.0e+00 0.0e+00  0  1  0  0  0   0  1  0  0  0 22793
VecCopy               49 1.0 1.5044e-04 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecSet               211 1.0 2.2817e-04 1.2 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecAXPY               10 1.0 7.8201e-05 1.2 1.04e+05 1.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0 29071
VecAYPX              320 1.0 1.5337e-03 1.0 1.40e+06 1.0 0.0e+00 0.0e+00 0.0e+00  1  3  0  0  0   1  3  0  0  0 19965
VecAXPBYCZ           160 1.0 1.2972e-03 1.0 2.79e+06 1.0 0.0e+00 0.0e+00 0.0e+00  1  6  0  0  0   1  6  0  0  0 47209
VecMAXPY              98 1.0 2.2635e-03 1.1 4.92e+06 1.0 0.0e+00 0.0e+00 0.0e+00  1 11  0  0  0   1 11  0  0  0 47680
VecAssemblyBegin      14 1.0 1.5211e-03 2.5 0.00e+00 0.0 0.0e+00 0.0e+00 3.6e+01  1  0  0  0  5   1  0  0  0  5     0
VecAssemblyEnd        14 1.0 1.5497e-05 2.2 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecPointwiseMult      44 1.0 2.9850e-04 1.4 1.54e+05 1.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0 11284
VecScatterBegin      429 1.0 2.3854e-03 2.3 0.00e+00 0.0 1.7e+04 2.1e+03 0.0e+00  1  0 74 78  0   1  0 74 79  0     0
VecScatterEnd        429 1.0 3.9475e-03 1.3 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  2  0  0  0  0   2  0  0  0  0     0
VecSetRandom           4 1.0 7.5912e-04 1.3 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecNormalize          98 1.0 5.3647e-03 1.1 1.28e+06 1.0 0.0e+00 0.0e+00 9.8e+01  3  3  0  0 14   3  3  0  0 14  5233
KSPGMRESOrthog        89 1.0 7.5228e-03 1.4 8.29e+06 1.0 0.0e+00 0.0e+00 8.9e+01  3 19  0  0 13   3 19  0  0 13 24181
KSPSetUp              15 1.0 1.4267e-03 1.3 0.00e+00 0.0 0.0e+00 0.0e+00 8.0e+00  1  0  0  0  1   1  0  0  0  1     0
KSPSolve               1 1.0 1.7168e-01 1.0 4.36e+07 1.0 2.3e+04 1.9e+03 6.8e+02 92100 99 99 98  98100100100 99  5540
PCGAMGGraph_AGG        4 1.0 2.6743e-02 1.0 1.73e+05 1.0 4.9e+02 1.1e+03 4.8e+01 14  0  2  1  7  15  0  2  1  7   141
PCGAMGCoarse_AGG       4 1.0 3.4651e-02 1.0 6.05e+05 1.0 1.7e+03 2.6e+03 5.3e+01 19  1  8 10  8  20  1  8 10  8   383
PCGAMGProl_AGG         4 1.0 8.0829e-03 1.0 0.00e+00 0.0 8.4e+02 1.5e+03 9.6e+01  4  0  4  3 14   5  0  4  3 14     0
PCGAMGPOpt_AGG         4 1.0 2.6408e-02 1.0 5.83e+06 1.0 2.7e+03 1.8e+03 1.9e+02 14 13 12 10 27  15 13 12 10 27  4827
GAMG: createProl       4 1.0 9.6011e-02 1.0 6.61e+06 1.0 5.8e+03 1.9e+03 3.8e+02 51 15 25 25 55  55 15 25 25 56  1505
  Graph                8 1.0 2.6509e-02 1.0 1.73e+05 1.0 4.9e+02 1.1e+03 4.8e+01 14  0  2  1  7  15  0  2  1  7   142
  MIS/Agg              4 1.0 3.2272e-03 1.2 0.00e+00 0.0 1.3e+03 1.1e+03 1.8e+01  2  0  6  3  3   2  0  6  3  3     0
  SA: col data         4 1.0 2.2800e-03 1.0 0.00e+00 0.0 3.3e+02 3.2e+03 4.0e+01  1  0  1  2  6   1  0  1  2  6     0
  SA: frmProl0         4 1.0 4.9379e-03 1.0 0.00e+00 0.0 5.2e+02 3.5e+02 4.0e+01  3  0  2  0  6   3  0  2  0  6     0
  SA: smooth           4 1.0 2.6406e-02 1.0 5.83e+06 1.0 2.7e+03 1.8e+03 1.9e+02 14 13 12 10 27  15 13 12 10 27  4827
GAMG: partLevel        4 1.0 2.3223e-02 1.0 1.14e+06 1.1 2.7e+03 1.9e+03 1.7e+02 12  3 12 11 25  13  3 12 11 25  1044
  repartition          2 1.0 2.2793e-04 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 1.2e+01  0  0  0  0  2   0  0  0  0  2     0
  Invert-Sort          2 1.0 3.4189e-04 1.6 0.00e+00 0.0 0.0e+00 0.0e+00 8.0e+00  0  0  0  0  1   0  0  0  0  1     0
  Move A               2 1.0 1.3077e-03 1.0 0.00e+00 0.0 2.3e+02 9.8e+02 3.6e+01  1  0  1  1  5   1  0  1  1  5     0
  Move P               2 1.0 1.1868e-03 1.0 0.00e+00 0.0 1.2e+02 6.3e+01 3.6e+01  1  0  1  0  5   1  0  1  0  5     0
PCSetUp                2 1.0 1.2154e-01 1.0 7.74e+06 1.0 8.5e+03 1.9e+03 5.8e+02 65 18 36 36 83  69 18 36 36 84  1389
PCSetUpOnBlocks       10 1.0 1.9693e-04 3.3 2.68e+04 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0   136
PCApply               10 1.0 4.6758e-02 1.0 3.21e+07 1.0 1.4e+04 1.9e+03 8.4e+01 25 73 62 60 12  27 73 62 60 12 14987
SFSetGraph             4 1.0 1.1826e-04 2.6 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFBcastBegin          26 1.0 1.2026e-03 2.0 0.00e+00 0.0 1.3e+03 1.1e+03 0.0e+00  0  0  6  3  0   1  0  6  3  0     0
SFBcastEnd            26 1.0 3.8409e-04 3.2 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
BuildTwoSided          4 1.0 1.0309e-03 3.2 0.00e+00 0.0 8.2e+01 4.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0

--- Event Stage 1: Assembly

MatAssemblyBegin       1 1.0 5.0600e-0351.1 0.00e+00 0.0 0.0e+00 0.0e+00 2.0e+00  1  0  0  0  0  18  0  0  0 20     0
MatAssemblyEnd         1 1.0 2.4519e-03 1.0 0.00e+00 0.0 8.4e+01 1.0e+03 8.0e+00  1  0  0  0  1  22  0100100 80     0
VecSet                 1 1.0 9.0599e-06 1.5 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
------------------------------------------------------------------------------------------------------------------------

Memory usage is given in bytes:

Object Type          Creations   Destructions     Memory  Descendants' Mem.
Reports information only for process 0.

--- Event Stage 0: Main Stage

              Matrix   122            122     11519580     0.
      Matrix Coarsen     4              4         2512     0.
              Vector   256            257      7217544     0.
      Vector Scatter    27             28        30288     0.
           Index Set    69             69        67612     0.
       Krylov Solver    15             15       267632     0.
      Preconditioner    15             15        14012     0.
         PetscRandom     1              1          638     0.
Star Forest Bipartite Graph     4              4         3392     0.
              Viewer     1              0            0     0.

--- Event Stage 1: Assembly

              Vector     2              1         1648     0.
      Vector Scatter     1              0            0     0.
           Index Set     2              2         3600     0.
========================================================================================================================
Average time to get PetscTime(): 9.53674e-08
Average time for MPI_Barrier(): 9.58443e-06
Average time for zero size MPI_Send(): 7.41265e-06
#PETSc Option Table entries:
-log_view :results/gamg/gamg_11_512.txt
-m 512
-n 512
-pc_type gamg
#End of PETSc Option Table entries
Compiled without FORTRAN kernels
Compiled with full precision matrices (default)
sizeof(short) 2 sizeof(int) 4 sizeof(long) 8 sizeof(void*) 8 sizeof(PetscScalar) 8 sizeof(PetscInt) 4
Configure options: --with-cc=mpicc --with-cxx=mpicxx --with-fc=mpif90 --download-fblaslapack --with-debugging=0 --download-superlu_dist --download-parmetis --download-metis --download-ptscotch --download-hypre
-----------------------------------------
Libraries compiled on Mon Aug 28 20:21:00 2017 on l35 
Machine characteristics: Linux-3.10.0-327.36.3.el7.x86_64-x86_64-with-centos-7.2.1511-Core
Using PETSc directory: /home/lv71041/selinger3d/petsc
Using PETSc arch: arch-linux2-c-opt
-----------------------------------------

Using C compiler: mpicc  -fPIC  -Wall -Wwrite-strings -Wno-strict-aliasing -Wno-unknown-pragmas -fvisibility=hidden -g -O  ${COPTFLAGS} ${CFLAGS}
Using Fortran compiler: mpif90  -fPIC -Wall -ffree-line-length-0 -Wno-unused-dummy-argument -g -O   ${FOPTFLAGS} ${FFLAGS} 
-----------------------------------------

Using include paths: -I/home/lv71041/selinger3d/petsc/arch-linux2-c-opt/include -I/home/lv71041/selinger3d/petsc/include -I/home/lv71041/selinger3d/petsc/include -I/home/lv71041/selinger3d/petsc/arch-linux2-c-opt/include
-----------------------------------------

Using C linker: mpicc
Using Fortran linker: mpif90
Using libraries: -Wl,-rpath,/home/lv71041/selinger3d/petsc/arch-linux2-c-opt/lib -L/home/lv71041/selinger3d/petsc/arch-linux2-c-opt/lib -lpetsc -Wl,-rpath,/home/lv71041/selinger3d/petsc/arch-linux2-c-opt/lib -L/home/lv71041/selinger3d/petsc/arch-linux2-c-opt/lib -Wl,-rpath,/cm/shared/apps/intel/compilers_and_libraries_2017.4.196/linux/mpi/intel64/lib/debug_mt -L/cm/shared/apps/intel/compilers_and_libraries_2017.4.196/linux/mpi/intel64/lib/debug_mt -Wl,-rpath,/cm/shared/apps/intel/compilers_and_libraries_2017.4.196/linux/mpi/intel64/lib -L/cm/shared/apps/intel/compilers_and_libraries_2017.4.196/linux/mpi/intel64/lib -Wl,-rpath,/usr/lib/gcc/x86_64-redhat-linux/4.8.5 -L/usr/lib/gcc/x86_64-redhat-linux/4.8.5 -Wl,-rpath,/cm/shared/apps/intel/compilers_and_libraries_2017.4.196/linux/tbb/lib/intel64/gcc4.1 -L/cm/shared/apps/intel/compilers_and_libraries_2017.4.196/linux/tbb/lib/intel64/gcc4.1 -Wl,-rpath,/cm/shared/apps/intel/compilers_and_libraries_2017.4.196/linux/compiler/lib/intel64_lin -L/cm/shared/apps/intel/compilers_and_libraries_2017.4.196/linux/compiler/lib/intel64_lin -Wl,-rpath,/cm/shared/apps/intel/compilers_and_libraries_2017.4.196/linux/daal/lib/intel64_lin -L/cm/shared/apps/intel/compilers_and_libraries_2017.4.196/linux/daal/lib/intel64_lin -Wl,-rpath,/cm/shared/apps/intel/compilers_and_libraries_2017.4.196/linux/tbb/lib/intel64/gcc4.4 -L/cm/shared/apps/intel/compilers_and_libraries_2017.4.196/linux/tbb/lib/intel64/gcc4.4 -Wl,-rpath,/cm/shared/apps/intel/compilers_and_libraries_2017.4.196/linux/compiler/lib/intel64 -L/cm/shared/apps/intel/compilers_and_libraries_2017.4.196/linux/compiler/lib/intel64 -Wl,-rpath,/cm/shared/apps/intel/compilers_and_libraries_2017.4.196/linux/ipp/lib/intel64 -L/cm/shared/apps/intel/compilers_and_libraries_2017.4.196/linux/ipp/lib/intel64 -Wl,-rpath,/opt/sw/x86_64/glibc-2.17/ivybridge-ep/valgrind/3.12.0/lib -L/opt/sw/x86_64/glibc-2.17/ivybridge-ep/valgrind/3.12.0/lib -Wl,-rpath,/cm/shared/apps/slurm/current/lib -L/cm/shared/apps/slurm/current/lib -Wl,-rpath,/cm/shared/apps/slurm/current/lib/slurm -L/cm/shared/apps/slurm/current/lib/slurm -Wl,-rpath,/opt/intel/mpi-rt/2107.0.0/intel64/lib/debug_mt -Wl,-rpath,/opt/intel/mpi-rt/2017.0.0/intel64/lib -Wl,-rpath,/opt/intel/mpi-rt/2017.0.0/intel64/lib/debug_mt -lsuperlu_dist -lparmetis -lmetis -lHYPRE -lmpicxx -lstdc++ -lm -lflapack -lfblas -lptesmumps -lptscotch -lptscotcherr -lscotch -lscotcherr -lX11 -lhwloc -lssl -lcrypto -lm -lgfortran -lm -lgfortran -lm -lquadmath -lmpicxx -lstdc++ -lm -lrt -lm -lpthread -lz -ldl -lmpifort -lmpi -lmpigi -lrt -lpthread -lgcc_s -ldl
-----------------------------------------

