************************************************************************************************************************
***             WIDEN YOUR WINDOW TO 120 CHARACTERS.  Use 'enscript -r -fCourier9' to print this document            ***
************************************************************************************************************************

---------------------------------------------- PETSc Performance Summary: ----------------------------------------------

ex2 on a arch-linux2-c-opt named n16-056 with 4 processors, by selinger3d Fri Sep  1 22:03:13 2017
Using Petsc Release Version 3.7.6, unknown 

                         Max       Max/Min        Avg      Total 
Time (sec):           2.567e+00      1.00018   2.566e+00
Objects:              5.900e+02      1.00340   5.885e+02
Flops:                1.039e+09      1.00326   1.037e+09  4.149e+09
Flops/sec:            4.048e+08      1.00345   4.041e+08  1.617e+09
MPI Messages:         1.524e+03      1.83554   1.185e+03  4.739e+03
MPI Message Lengths:  4.770e+06      2.00252   3.019e+03  1.431e+07
MPI Reductions:       7.680e+02      1.00000

Flop counting convention: 1 flop = 1 real number operation of type (multiply/divide/add/subtract)
                            e.g., VecAXPY() for real vectors of length N --> 2N flops
                            and VecAXPY() for complex vectors of length N --> 8N flops

Summary of Stages:   ----- Time ------  ----- Flops -----  --- Messages ---  -- Message Lengths --  -- Reductions --
                        Avg     %Total     Avg     %Total   counts   %Total     Avg         %Total   counts   %Total 
 0:      Main Stage: 2.4346e+00  94.9%  4.1486e+09 100.0%  4.727e+03  99.7%  3.014e+03       99.8%  7.570e+02  98.6% 
 1:        Assembly: 1.3169e-01   5.1%  0.0000e+00   0.0%  1.200e+01   0.3%  5.191e+00        0.2%  1.000e+01   1.3% 

------------------------------------------------------------------------------------------------------------------------
See the 'Profiling' chapter of the users' manual for details on interpreting output.
Phase summary info:
   Count: number of times phase was executed
   Time and Flops: Max - maximum over all processors
                   Ratio - ratio of maximum to minimum over all processors
   Mess: number of messages sent
   Avg. len: average message length (bytes)
   Reduct: number of global reductions
   Global: entire computation
   Stage: stages of a computation. Set stages with PetscLogStagePush() and PetscLogStagePop().
      %T - percent time in this phase         %F - percent flops in this phase
      %M - percent messages in this phase     %L - percent message lengths in this phase
      %R - percent reductions in this phase
   Total Mflop/s: 10e-6 * (sum of flops over all processors)/(max time over all processors)
------------------------------------------------------------------------------------------------------------------------
Event                Count      Time (sec)     Flops                             --- Global ---  --- Stage ---   Total
                   Max Ratio  Max     Ratio   Max  Ratio  Mess   Avg len Reduct  %T %F %M %L %R  %T %F %M %L %R Mflop/s
------------------------------------------------------------------------------------------------------------------------

--- Event Stage 0: Main Stage

MatMult              441 1.0 3.4186e-01 1.2 3.23e+08 1.0 3.0e+03 3.3e+03 0.0e+00 12 31 63 69  0  13 31 63 69  0  3771
MatMultAdd            55 1.0 2.7336e-02 1.1 1.78e+07 1.0 3.0e+02 1.1e+03 0.0e+00  1  2  6  2  0   1  2  6  2  0  2595
MatMultTranspose      55 1.0 3.6799e-02 1.1 1.78e+07 1.0 3.0e+02 1.1e+03 0.0e+00  1  2  6  2  0   1  2  6  2  0  1928
MatSolve              11 0.0 2.8849e-05 0.0 3.44e+03 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0   119
MatSOR               385 1.0 4.8957e-01 1.3 2.89e+08 1.0 0.0e+00 0.0e+00 0.0e+00 18 28  0  0  0  19 28  0  0  0  2350
MatLUFactorSym         1 1.0 2.1935e-05 1.6 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
MatLUFactorNum         1 1.0 1.1206e-05 5.9 1.26e+03 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0   112
MatConvert             5 1.0 1.5499e-02 1.3 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  1  0  0  0  0   1  0  0  0  0     0
MatScale              15 1.0 1.0613e-02 1.4 5.37e+06 1.0 3.4e+01 3.2e+03 0.0e+00  0  1  1  1  0   0  1  1  1  0  2022
MatResidual           55 1.0 5.1909e-02 1.5 4.13e+07 1.0 3.7e+02 3.2e+03 0.0e+00  2  4  8  8  0   2  4  8  8  0  3180
MatAssemblyBegin      94 1.0 6.1343e-0226.2 0.00e+00 0.0 1.6e+02 4.6e+03 5.8e+01  1  0  3  5  8   1  0  3  5  8     0
MatAssemblyEnd        94 1.0 1.5725e-01 1.2 0.00e+00 0.0 2.7e+02 5.7e+02 1.8e+02  5  0  6  1 24   6  0  6  1 24     0
MatGetRow         917874 1.0 9.1252e-02 1.2 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  3  0  0  0  0   4  0  0  0  0     0
MatGetRowIJ            1 0.0 5.9605e-06 0.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
MatGetSubMatrix        2 1.0 3.5501e-04 1.0 0.00e+00 0.0 2.1e+01 8.6e+01 3.4e+01  0  0  0  0  4   0  0  0  0  4     0
MatGetOrdering         1 0.0 4.7922e-05 0.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
MatCoarsen             5 1.0 2.6778e-02 1.3 0.00e+00 0.0 2.0e+02 2.0e+03 1.1e+01  1  0  4  3  1   1  0  4  3  1     0
MatZeroEntries         5 1.0 7.1430e-04 1.2 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
MatAXPY                5 1.0 7.6372e-02 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 1.0e+01  3  0  0  0  1   3  0  0  0  1     0
MatMatMult             5 1.0 1.0311e-01 1.0 3.76e+06 1.0 2.0e+02 1.7e+03 8.0e+01  4  0  4  2 10   4  0  4  2 11   146
MatMatMultSym          5 1.0 8.2160e-02 1.0 0.00e+00 0.0 1.7e+02 1.4e+03 7.0e+01  3  0  4  2  9   3  0  4  2  9     0
MatMatMultNum          5 1.0 2.1483e-02 1.0 3.76e+06 1.0 3.4e+01 3.2e+03 1.0e+01  1  0  1  1  1   1  0  1  1  1   699
MatPtAP                5 1.0 2.2227e-01 1.0 2.41e+07 1.0 3.9e+02 4.1e+03 8.5e+01  9  2  8 11 11   9  2  8 11 11   432
MatPtAPSymbolic        5 1.0 1.6467e-01 1.0 0.00e+00 0.0 2.0e+02 4.3e+03 3.5e+01  6  0  4  6  5   7  0  4  6  5     0
MatPtAPNumeric         5 1.0 5.7593e-02 1.0 2.41e+07 1.0 1.8e+02 3.9e+03 5.0e+01  2  2  4  5  7   2  2  4  5  7  1667
MatTrnMatMult          1 1.0 3.4215e-01 1.0 1.31e+07 1.0 3.6e+01 1.3e+04 1.9e+01 13  1  1  3  2  14  1  1  3  3   153
MatTrnMatMultSym       1 1.0 2.2852e-01 1.0 0.00e+00 0.0 3.0e+01 7.4e+03 1.7e+01  9  0  1  2  2   9  0  1  2  2     0
MatTrnMatMultNum       1 1.0 1.1372e-01 1.0 1.31e+07 1.0 6.0e+00 4.1e+04 2.0e+00  4  1  0  2  0   5  1  0  2  0   461
MatGetLocalMat        17 1.0 4.3902e-02 1.2 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  2  0  0  0  0   2  0  0  0  0     0
MatGetBrAoCol         15 1.0 4.3113e-03 1.7 0.00e+00 0.0 2.4e+02 4.2e+03 0.0e+00  0  0  5  7  0   0  0  5  7  0     0
VecMDot              110 1.0 1.4819e-01 1.9 9.61e+07 1.0 0.0e+00 0.0e+00 1.1e+02  4  9  0  0 14   4  9  0  0 15  2594
VecNorm              122 1.0 4.4765e-02 2.5 1.98e+07 1.0 0.0e+00 0.0e+00 1.2e+02  1  2  0  0 16   1  2  0  0 16  1764
VecScale             121 1.0 6.1569e-03 1.1 9.61e+06 1.0 0.0e+00 0.0e+00 0.0e+00  0  1  0  0  0   0  1  0  0  0  6243
VecCopy               66 1.0 1.1843e-02 1.7 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecSet               268 1.0 1.9794e-02 2.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  1  0  0  0  0   1  0  0  0  0     0
VecAXPY               12 1.0 4.4417e-03 3.0 2.27e+06 1.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0  2046
VecAYPX              440 1.0 4.1230e-02 1.3 3.37e+07 1.0 0.0e+00 0.0e+00 0.0e+00  1  3  0  0  0   1  3  0  0  0  3262
VecAXPBYCZ           220 1.0 3.0631e-02 1.1 6.73e+07 1.0 0.0e+00 0.0e+00 0.0e+00  1  6  0  0  0   1  6  0  0  0  8783
VecMAXPY             121 1.0 5.5640e-02 1.3 1.14e+08 1.0 0.0e+00 0.0e+00 0.0e+00  2 11  0  0  0   2 11  0  0  0  8164
VecAssemblyBegin      15 1.0 3.0704e-0312.4 0.00e+00 0.0 0.0e+00 0.0e+00 4.2e+01  0  0  0  0  5   0  0  0  0  6     0
VecAssemblyEnd        15 1.0 1.3828e-05 1.4 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecPointwiseMult      55 1.0 6.6679e-03 1.5 3.37e+06 1.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0  2017
VecScatterBegin      572 1.0 3.6397e-03 1.6 0.00e+00 0.0 3.7e+03 3.1e+03 0.0e+00  0  0 78 80  0   0  0 79 80  0     0
VecScatterEnd        572 1.0 1.2344e-0128.8 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  2  0  0  0  0   2  0  0  0  0     0
VecSetRandom           5 1.0 1.0218e-02 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecNormalize         121 1.0 4.5983e-02 1.9 2.88e+07 1.0 0.0e+00 0.0e+00 1.2e+02  1  3  0  0 16   1  3  0  0 16  2508
KSPGMRESOrthog       110 1.0 1.8401e-01 1.5 1.92e+08 1.0 0.0e+00 0.0e+00 1.1e+02  6 19  0  0 14   6 19  0  0 15  4178
KSPSetUp              18 1.0 1.9403e-02 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 1.0e+01  1  0  0  0  1   1  0  0  0  1     0
KSPSolve               1 1.0 2.4054e+00 1.0 1.04e+09 1.0 4.7e+03 3.0e+03 7.5e+02 94100100 99 98  99100100100 99  1719
PCGAMGGraph_AGG        5 1.0 2.9537e-01 1.0 3.76e+06 1.0 1.0e+02 1.6e+03 6.0e+01 12  0  2  1  8  12  0  2  1  8    51
PCGAMGCoarse_AGG       5 1.0 4.3541e-01 1.0 1.31e+07 1.0 2.6e+02 5.0e+03 4.6e+01 17  1  6  9  6  18  1  6  9  6   120
PCGAMGProl_AGG         5 1.0 8.7362e-02 1.0 0.00e+00 0.0 1.6e+02 2.3e+03 1.2e+02  3  0  3  3 16   3  0  3  3 16     0
PCGAMGPOpt_AGG         5 1.0 2.9977e-01 1.0 1.27e+08 1.0 5.4e+02 2.6e+03 2.4e+02 12 12 11 10 31  12 12 12 10 31  1698
GAMG: createProl       5 1.0 1.1158e+00 1.0 1.44e+08 1.0 1.1e+03 3.1e+03 4.6e+02 43 14 23 23 60  46 14 23 23 61   517
  Graph               10 1.0 2.9496e-01 1.0 3.76e+06 1.0 1.0e+02 1.6e+03 6.0e+01 11  0  2  1  8  12  0  2  1  8    51
  MIS/Agg              5 1.0 2.6854e-02 1.3 0.00e+00 0.0 2.0e+02 2.0e+03 1.1e+01  1  0  4  3  1   1  0  4  3  1     0
  SA: col data         5 1.0 1.9670e-02 1.0 0.00e+00 0.0 6.8e+01 4.6e+03 5.0e+01  1  0  1  2  7   1  0  1  2  7     0
  SA: frmProl0         5 1.0 5.9620e-02 1.0 0.00e+00 0.0 9.0e+01 6.0e+02 5.0e+01  2  0  2  0  7   2  0  2  0  7     0
  SA: smooth           5 1.0 2.9977e-01 1.0 1.27e+08 1.0 5.4e+02 2.6e+03 2.4e+02 12 12 11 10 31  12 12 12 10 31  1698
GAMG: partLevel        5 1.0 2.2292e-01 1.0 2.41e+07 1.0 4.2e+02 3.8e+03 1.4e+02  9  2  9 11 18   9  2  9 11 18   431
  repartition          2 1.0 5.4121e-05 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 6.0e+00  0  0  0  0  1   0  0  0  0  1     0
  Invert-Sort          1 1.0 8.4162e-05 1.6 0.00e+00 0.0 0.0e+00 0.0e+00 4.0e+00  0  0  0  0  1   0  0  0  0  1     0
  Move A               1 1.0 2.3484e-04 1.0 0.00e+00 0.0 1.5e+01 1.1e+02 1.8e+01  0  0  0  0  2   0  0  0  0  2     0
  Move P               1 1.0 1.8907e-04 1.0 0.00e+00 0.0 6.0e+00 2.1e+01 1.8e+01  0  0  0  0  2   0  0  0  0  2     0
PCSetUp                2 1.0 1.3517e+00 1.0 1.68e+08 1.0 1.5e+03 3.3e+03 6.3e+02 53 16 31 34 82  55 16 31 34 83   497
PCSetUpOnBlocks       11 1.0 1.3518e-04 1.4 1.26e+03 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     9
PCApply               11 1.0 9.8400e-01 1.0 7.72e+08 1.0 3.2e+03 2.8e+03 1.0e+02 38 74 67 62 14  40 74 67 62 14  3130
SFSetGraph             5 1.0 1.5831e-04 2.3 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFBcastBegin          21 1.0 6.2957e-0315.6 0.00e+00 0.0 2.0e+02 2.0e+03 0.0e+00  0  0  4  3  0   0  0  4  3  0     0
SFBcastEnd            21 1.0 3.6595e-0317.8 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
BuildTwoSided          5 1.0 6.1133e-0332.4 0.00e+00 0.0 1.7e+01 4.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0

--- Event Stage 1: Assembly

MatAssemblyBegin       1 1.0 4.8273e-021007.3 0.00e+00 0.0 0.0e+00 0.0e+00 2.0e+00  0  0  0  0  0   9  0  0  0 20     0
MatAssemblyEnd         1 1.0 1.7923e-02 1.0 0.00e+00 0.0 1.2e+01 2.0e+03 8.0e+00  1  0  0  0  1  14  0100100 80     0
VecSet                 1 1.0 7.8678e-06 1.3 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
------------------------------------------------------------------------------------------------------------------------

Memory usage is given in bytes:

Object Type          Creations   Destructions     Memory  Descendants' Mem.
Reports information only for process 0.

--- Event Stage 0: Main Stage

              Matrix   138            138    244740948     0.
      Matrix Coarsen     5              5         3140     0.
              Vector   304            305    148404312     0.
      Vector Scatter    29             30        32184     0.
           Index Set    66             66        77596     0.
       Krylov Solver    18             18       329360     0.
      Preconditioner    18             18        16708     0.
         PetscRandom     1              1          638     0.
Star Forest Bipartite Graph     5              5         4240     0.
              Viewer     1              0            0     0.

--- Event Stage 1: Assembly

              Vector     2              1         1648     0.
      Vector Scatter     1              0            0     0.
           Index Set     2              2         5648     0.
========================================================================================================================
Average time to get PetscTime(): 0.
Average time for MPI_Barrier(): 1.19209e-06
Average time for zero size MPI_Send(): 8.76188e-06
#PETSc Option Table entries:
-ksp_max_it 50
-log_view :weak_ex2/n4_512_gamg.txt
-m 1024
-n 1024
-pc_type gamg
#End of PETSc Option Table entries
Compiled without FORTRAN kernels
Compiled with full precision matrices (default)
sizeof(short) 2 sizeof(int) 4 sizeof(long) 8 sizeof(void*) 8 sizeof(PetscScalar) 8 sizeof(PetscInt) 4
Configure options: --with-cc=mpicc --with-cxx=mpicxx --with-fc=mpif90 --download-fblaslapack --with-debugging=0 --download-superlu_dist --download-parmetis --download-metis --download-ptscotch --download-hypre
-----------------------------------------
Libraries compiled on Mon Aug 28 20:21:00 2017 on l35 
Machine characteristics: Linux-3.10.0-327.36.3.el7.x86_64-x86_64-with-centos-7.2.1511-Core
Using PETSc directory: /home/lv71041/selinger3d/petsc
Using PETSc arch: arch-linux2-c-opt
-----------------------------------------

Using C compiler: mpicc  -fPIC  -Wall -Wwrite-strings -Wno-strict-aliasing -Wno-unknown-pragmas -fvisibility=hidden -g -O  ${COPTFLAGS} ${CFLAGS}
Using Fortran compiler: mpif90  -fPIC -Wall -ffree-line-length-0 -Wno-unused-dummy-argument -g -O   ${FOPTFLAGS} ${FFLAGS} 
-----------------------------------------

Using include paths: -I/home/lv71041/selinger3d/petsc/arch-linux2-c-opt/include -I/home/lv71041/selinger3d/petsc/include -I/home/lv71041/selinger3d/petsc/include -I/home/lv71041/selinger3d/petsc/arch-linux2-c-opt/include
-----------------------------------------

Using C linker: mpicc
Using Fortran linker: mpif90
Using libraries: -Wl,-rpath,/home/lv71041/selinger3d/petsc/arch-linux2-c-opt/lib -L/home/lv71041/selinger3d/petsc/arch-linux2-c-opt/lib -lpetsc -Wl,-rpath,/home/lv71041/selinger3d/petsc/arch-linux2-c-opt/lib -L/home/lv71041/selinger3d/petsc/arch-linux2-c-opt/lib -Wl,-rpath,/cm/shared/apps/intel/compilers_and_libraries_2017.4.196/linux/mpi/intel64/lib/debug_mt -L/cm/shared/apps/intel/compilers_and_libraries_2017.4.196/linux/mpi/intel64/lib/debug_mt -Wl,-rpath,/cm/shared/apps/intel/compilers_and_libraries_2017.4.196/linux/mpi/intel64/lib -L/cm/shared/apps/intel/compilers_and_libraries_2017.4.196/linux/mpi/intel64/lib -Wl,-rpath,/usr/lib/gcc/x86_64-redhat-linux/4.8.5 -L/usr/lib/gcc/x86_64-redhat-linux/4.8.5 -Wl,-rpath,/cm/shared/apps/intel/compilers_and_libraries_2017.4.196/linux/tbb/lib/intel64/gcc4.1 -L/cm/shared/apps/intel/compilers_and_libraries_2017.4.196/linux/tbb/lib/intel64/gcc4.1 -Wl,-rpath,/cm/shared/apps/intel/compilers_and_libraries_2017.4.196/linux/compiler/lib/intel64_lin -L/cm/shared/apps/intel/compilers_and_libraries_2017.4.196/linux/compiler/lib/intel64_lin -Wl,-rpath,/cm/shared/apps/intel/compilers_and_libraries_2017.4.196/linux/daal/lib/intel64_lin -L/cm/shared/apps/intel/compilers_and_libraries_2017.4.196/linux/daal/lib/intel64_lin -Wl,-rpath,/cm/shared/apps/intel/compilers_and_libraries_2017.4.196/linux/tbb/lib/intel64/gcc4.4 -L/cm/shared/apps/intel/compilers_and_libraries_2017.4.196/linux/tbb/lib/intel64/gcc4.4 -Wl,-rpath,/cm/shared/apps/intel/compilers_and_libraries_2017.4.196/linux/compiler/lib/intel64 -L/cm/shared/apps/intel/compilers_and_libraries_2017.4.196/linux/compiler/lib/intel64 -Wl,-rpath,/cm/shared/apps/intel/compilers_and_libraries_2017.4.196/linux/ipp/lib/intel64 -L/cm/shared/apps/intel/compilers_and_libraries_2017.4.196/linux/ipp/lib/intel64 -Wl,-rpath,/opt/sw/x86_64/glibc-2.17/ivybridge-ep/valgrind/3.12.0/lib -L/opt/sw/x86_64/glibc-2.17/ivybridge-ep/valgrind/3.12.0/lib -Wl,-rpath,/cm/shared/apps/slurm/current/lib -L/cm/shared/apps/slurm/current/lib -Wl,-rpath,/cm/shared/apps/slurm/current/lib/slurm -L/cm/shared/apps/slurm/current/lib/slurm -Wl,-rpath,/opt/intel/mpi-rt/2107.0.0/intel64/lib/debug_mt -Wl,-rpath,/opt/intel/mpi-rt/2017.0.0/intel64/lib -Wl,-rpath,/opt/intel/mpi-rt/2017.0.0/intel64/lib/debug_mt -lsuperlu_dist -lparmetis -lmetis -lHYPRE -lmpicxx -lstdc++ -lm -lflapack -lfblas -lptesmumps -lptscotch -lptscotcherr -lscotch -lscotcherr -lX11 -lhwloc -lssl -lcrypto -lm -lgfortran -lm -lgfortran -lm -lquadmath -lmpicxx -lstdc++ -lm -lrt -lm -lpthread -lz -ldl -lmpifort -lmpi -lmpigi -lrt -lpthread -lgcc_s -ldl
-----------------------------------------

